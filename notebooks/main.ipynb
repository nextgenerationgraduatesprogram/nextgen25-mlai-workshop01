{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch utils directory from GitHub repo (workaround for using the utils in colab)\n",
    "!curl -sL https://github.com/nextgenerationgraduatesprogram/nextgen25-mlai-workshop01/archive/refs/heads/main.zip -o repo.zip\n",
    "!unzip -q repo.zip \"nextgen25-mlai-workshop01-main/utils/*\" -d .\n",
    "!rm -rf ./utils\n",
    "!mv nextgen25-mlai-workshop01-main/utils ./utils -f\n",
    "!rm -rf nextgen25-mlai-workshop01-main repo.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565dcb4d",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    ü§ñ MLAI Workshop #01\n",
    "</h1>\n",
    "\n",
    "Across many machine learning courses and tutorials, I've found the focus is often on using a specific architecture, implementing a certain model, or using a given pipeline - and this is useful. But I find its much less common for those resources to step back and ask:\n",
    "- What is does a model represent?\n",
    "- What does it mean to learn from data?\n",
    "- Why does this work ‚Äî and when does it fail?\n",
    " \n",
    "The goal of this series of workshops isn‚Äôt just to show you how to use machine learning models - it's to explore these questions - to facilitate develop a deeper understanding of the fundamentals that underpin how and why machine learning works.\n",
    "\n",
    "üí¨ *Question for the audience! Who here works with machine learning regularly and who is new to this space?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b21d3c",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    üóìÔ∏è Agenda\n",
    "</h2>\n",
    "\n",
    "1. **What are functions?**\n",
    "    Understand functions as the foundation of machine learning ‚Äî mappings from input to output that describe real-world processes.\n",
    "\n",
    "2. **How do we represent functions?**\n",
    "    Explore the idea of a **hypothesis space** and how different model structures (linear, nonlinear, polynomial) encode assumptions about the functions we can learn. We'll work through examples to visualize how different choices affect what we can represent.\n",
    "\n",
    "3. **How do we calibrate the function?**\n",
    "    Learn how we use **data** to constrain our models. We'll look at observations as evidence and introduce the concept of a loss function to quantify how well a model matches the data.\n",
    "\n",
    "4. **What does the loss landscape look like?**\n",
    "    Viewing the loss function as a landscape ‚Äî we can visualize how different parameter choices influence model performance. We‚Äôll use 2D and 3D plots to understand how gradient descent searches for good solutions.\n",
    "\n",
    "5. **How do we navigate through the loss landscape?**\n",
    "    We can explore this loss landscape using optimization techniques - allowing us to iteratively refine the parameters of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d617775",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49301159",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    Section 1: Functions\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4bda5",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    üìà Section 1A: What are functions and why should I care?\n",
    "</h3>\n",
    "\n",
    "Functions describe the world - from physical phenomena such as the dynamics of protein folding and the behavior of fluids, to abstract processes like decision-making and natural language understanding - functions describe the world through relationships between inputs and outputs.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/nextgenerationgraduatesprogram/nextgen25-mlai-workshop01/raw/main/media/notebook/GraphCast_Forecast.jpg\" height=\"400\"/>\n",
    "    <p><em>Figure 1. GraphCast is a Google DeepModel model for faster and more accurate global weather forecasting.</em></p>\n",
    "</div>\n",
    "\n",
    "So what is a function? A function $f$ is an object that maps an input space $\\mathcal{X}$ to an output space $\\mathcal{Y}$:\n",
    "\n",
    "\\begin{align*}\n",
    "f: \\mathcal{X} \\to \\mathcal{Y} \\tag{1.1}\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6e95c",
   "metadata": {},
   "source": [
    "For example, the linear equation $f(x) = \\theta_{1} x + \\theta_{2}$ is a function that maps a given input $x \\in \\mathbb{R}$ in 1-D space to an output $y \\in \\mathbb{R}$ in 1-D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d690e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some function\n",
    "def f(x):\n",
    "    return -7.13 * x + 0.51\n",
    "\n",
    "# map the input to the output\n",
    "x = 1.5\n",
    "y = f(x)\n",
    "\n",
    "print(f\"f: {x:.2f} -> {y:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a46c5",
   "metadata": {},
   "source": [
    "However, functions can be more general than this. Consider weather forecasting, the evolution of the atmosphere could be considered a function i.e. there is a relationship between the current state and the future state.\n",
    "\n",
    "\\begin{align*}\n",
    "    f^{*}: \\mathcal{X}^{*} \\to \\mathcal{Y}^{*} \\tag{1.2} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $f^{*}$ represents the target function describing this relationship. (this may be a space of functions $\\mathcal{T}$)\n",
    "- $\\mathcal{X}^{*}$ represents the true current and/or historical atmospheric state.\n",
    "- $\\mathcal{Y}^{*}$ represents the true corresponding future atmospheric state.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/nextgenerationgraduatesprogram/nextgen25-mlai-workshop01/raw/main/media/notebook/GraphCast_Rollout.jpg\" height=\"400\"/>\n",
    "    <p><em>Figure 2. GraphCast takes as input the current atmospheric state and predicts the next state, this can be rolled out in an auto-regressive manner.</em></p>\n",
    "</div>\n",
    "\n",
    "The target function $f^{*}$ represents this true data generating process in its entirity. For example, the evolution of the atmosphere is governed by the laws of physics and encapsulates the physics of the system - from large-scale fluid dynamics to fine-grained thermodynamics. We often can't write down or compute $f^{*}$ directly, but we assume it exists and is responsible for generating the data we observe. \n",
    "\n",
    "üí¨ *Question for the audience! What sort of function/relationship are you assuming exists in your research? What are the inputs/predictors and what are the outputs/responses?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb89006",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    üìå Section 1B. Can we represent this function?\n",
    "</h3>\n",
    "\n",
    "Unfortunately, in most scenarios we don't have access to $f^{*}$ - if we did, we wouldn't be here today talking about machine learning. Instead, we often aim to approximate $f^{*}$ using our function $f$:\n",
    "\n",
    "\\begin{align*}\n",
    "    f \\approx f^{*} \\tag{1.3}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "We might also place constrains on how well we approximate $f \\approx f^{*}$, such that it can be useful in certain scenarios. We call this set of functions the target space $\\mathcal{T}$:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{T} = \\left\\{ f \\in \\mathcal{H} \\,|\\, \\mathcal{L}(f, f^{*}) \\leq \\epsilon \\text{ and f satisfies additional constraints} \\right\\} \\tag{1.4}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $\\mathcal{H}$ is the hypothesis space\n",
    "- $\\mathcal{L}(f, f^{*})$ is some function that evaluates the fit of the model\n",
    "- $\\epsilon$ is some evaluation metric threshold\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/nextgenerationgraduatesprogram/nextgen25-mlai-workshop01/raw/main/media/notebook/GraphCast_Error.png\" height=\"400\"/>\n",
    "    <p><em>Figure 3. GraphCast error distribution on a 12-hour forecast visualized across on mercator projection.</em></p>\n",
    "</div>\n",
    "\n",
    "For the example of weather forecasting, you might consider $\\mathcal{T}$ as the set of solutions that forecasts to a specified degree of accuracy after a 12-hour rollout $\\mathcal{L}_{\\text{forecast}}(f, f^{*}) \\leq \\epsilon$. To visialize this set of solutions we're going to use [Miro](https://miro.com/app/board/uXjVI44Nizk=/?share_link_id=794264052796)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236fe231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we might have a target function\n",
    "def f_target(x):\n",
    "    return ...\n",
    "\n",
    "# we might have an approximation\n",
    "def f_approx(x):\n",
    "    return ...\n",
    "\n",
    "# compute the distance in function or data space\n",
    "def loss(f_target, f_approx):\n",
    "    return ...\n",
    "\n",
    "# suitable function has distance < threshold\n",
    "eps = ...\n",
    "is_suitable = loss(..., ...) < eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5b39e",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    ü§î Hypothesis Space\n",
    "</h4>\n",
    "\n",
    "When we represent our function $f$ we usually separate this into it's structure and the parameterization. The hypothesis space $\\mathcal{H}$ defines the structure of the functions we're willing to consider for $f$ - i.e. what form we think the relationship has.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{H} = \\left\\{ f_{\\theta}: \\mathcal{X} \\to \\mathcal{Y} \\,|\\, f_{\\theta} \\text{ satisfies structural constraints} \\right\\} \\subseteq \\Theta \\tag{1.5}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $f_{\\theta}: \\mathcal{X} \\rightarrow \\mathcal{Y}$ represents a single function parameterized by parameters $\\theta$\n",
    "- $f_{\\theta} \\text{ satisfies structural constraints}$ represents our choice of modeling assumptions e.g. what sort of model we use\n",
    "- $\\Theta$ represents the parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c4967",
   "metadata": {},
   "source": [
    "For example, we might have a modelling problem where we hypothesise some linear equation as a suitable solution, in this case we can define $\\mathcal{H}$ as:\n",
    "\n",
    "\\begin{align*} \n",
    "    \\mathcal{H} = \\left\\{ f_{\\theta}: \\mathbb{R} \\to \\mathbb{R} \\,|\\, f_{\\theta}(x) = \\theta_{1} x + \\theta_{2} \\right\\}, \\quad\n",
    "    (\\theta_{1}, \\theta_{2}) \\in \\mathbb{R}^{2} \\tag{1.6}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict the set of functions to this form\n",
    "def H(a, b):\n",
    "    def f(x): # <--- defines the structure of our function\n",
    "        return a * x + b\n",
    "    return f\n",
    "\n",
    "# retireve a specific model from the hypothesis space\n",
    "f = H(a=0, b=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804a36c",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    üéõÔ∏è Parameter Space\n",
    "</h4>\n",
    "\n",
    "The parameter space $\\Theta$ is the set of all possible functions arising from different configurations of the parameters $\\theta \\in \\Theta$. \n",
    "\n",
    "\\begin{align*}\n",
    "    \\Theta = \\left\\{ \\theta \\in \\mathbb{R}^{p} \\,|\\, \\theta \\text{ satisfies model-specific constraints} \\right\\} \\tag{1.7}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $p$ is the number of parameters\n",
    "- $\\theta \\text{ satisfies model-specific constraints}$ represents additional constraints we place on the space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd2bfa1",
   "metadata": {},
   "source": [
    "The highlight the distinction between $\\mathcal{H}$ and $\\Theta$. There are lots of different functions we could define using a set of $\\theta$, this set of functions is usually much larger than our $\\mathcal{H}$. For example, we might use $(\\theta_{1}, \\theta_{2})$ to define a linear function:\n",
    "\n",
    "\\begin{align*} \n",
    "    \\mathcal{H} = \\left\\{ f_{\\theta}: \\mathbb{R} \\to \\mathbb{R} \\,|\\, f_{\\theta}(x) = \\theta_{1} x + \\theta_{2} \\right\\} \\tag{1.8}\n",
    "\\end{align*}\n",
    "\n",
    "But we could also use it to parameterize a logistic curve, even if this is not a part of $\\mathcal{H}$:\n",
    "\n",
    "\\begin{align*} \n",
    "    \\mathcal{H} = \\left\\{ f_{\\theta}: \\mathbb{R} \\to \\mathbb{R} \\,|\\, f_{\\theta}(x) = \\frac{1}{1 + \\exp^{\\theta_{1} (x - \\theta_{2})}} \\right\\} \\tag{1.9}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a91aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# a different hypothesis space with the same parameter space\n",
    "def another_H(a, b):\n",
    "    def f(x): # <-- \n",
    "        return 1 / (1 + np.exp(a * (x - b)))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89799948",
   "metadata": {},
   "source": [
    "We can also constrain the parameter space to restrict the models we can select from the hypothesis space. For example, we could define specific ranges of parameters for $\\theta$ rather than any real number - this may be relevant if you have constraints on what a parameter represents e.g. strength of the linear relationship.\n",
    "\n",
    "\\begin{align*} \n",
    "    \\theta_{1} \\in [0, 1], \\quad\n",
    "    \\theta_{2} \\in \\left\\{ 1,2 \\right\\} \\tag{1.10}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a set of parameters to consider (doesn't have to be explicit)\n",
    "a = [0, ..., 1]\n",
    "b = ...\n",
    "\n",
    "# define a hypothesis space with parameters constrained by parameter space\n",
    "def H(a, b):\n",
    "    assert a >= 0 and a <= 1, \"a must be in range [0,1]\" # <-- restricts the hypothesis space\n",
    "    assert b in [1,2], \"b must be in {1,2}\"\n",
    "    def f(x): # <--- use this form\n",
    "        return a * x + b\n",
    "    return f\n",
    "\n",
    "# invalid model based on parameter space constraints\n",
    "f = H(a=4.1, b=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7270a04",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    üß† What does this mean for our approximation?\n",
    "</h4>\n",
    "\n",
    "The hypothesis space $\\mathcal{H}$ describes the structure of the function and the parameter space $\\Theta$ allows us to describe what functions we can draw from that space. \n",
    "\n",
    "In certain scenarios, we might be able to use prior knowledge to design the hypothesis space - this is particularly useful in domains like physics, biology, or chemistry, where principled foundations exist. For example, in weather forecasting we know that atmospheric dynamics are (at least partially) governed by well-established physical laws ‚Äî such as the Navier‚ÄìStokes equations. This is completemented with approximations of more complex phenomena that we can't easily represent. This allows us to reduce our hypothesis space to a better set of guesses for the approximation.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{Y} = \\mathcal{X}_{t+1} = \\mathcal{X}_{t} + \\Delta t \\left[\\underbrace{\\mathcal{N}(\\mathcal{X}_{t})}_{\\text{Navier‚ÄìStokes dynamics}} + \\underbrace{\\mathbf{P}_\\theta(...)}_{\\text{Subgrid parameterizations}} \\right]\\tag{1.11}\n",
    "\\end{align*}\n",
    "\n",
    "üí¨ *Question for the audience! What sort of assumptions do you have about your data that inform the structure of your approximation function?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c4d67",
   "metadata": {},
   "source": [
    "For example, we have some target function $f^{*}$ that represents a data generating process, it is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "    f^*(x) = e^{-x^{2}} \\cdot \\sin(10.8 \\pi x + 0.41), \\quad \\text{for } x \\in [0, 1] \\tag{2.1}\n",
    "\\end{align*}\n",
    "\n",
    "We might have some prior knowledge that the generalized form of the function will have this form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a candidate hypothesis space\n",
    "def H(A, k, x_0, B, tau_0, phi_0, C, tau_1, phi_1, D):\n",
    "    def f(x): # <--- use this form\n",
    "        return A * np.exp(-k * (x - x_0)**2) * (B * np.sin(2 * np.pi * tau_0 + phi_0) + C * np.cos(2 * np.pi * tau_1 + phi_1)) + D\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7796af6c",
   "metadata": {},
   "source": [
    "However, for a vast number of problems, we don't even know what form the function should take...\n",
    "- What function describes a person‚Äôs reasoning process? \n",
    "- What function maps pixels in an image to its semantic meaning? \n",
    "- What function generates coherent video from a text prompt? \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/nextgenerationgraduatesprogram/nextgen25-mlai-workshop01/raw/main/media/notebook/Reasoning.png\" height=\"400\"/>\n",
    "    <p><em>Figure 3. What is the function for someones reasoning process?</em></p>\n",
    "</div>\n",
    "\n",
    "In such scenarios, we cannot rely on prior knowledge to explicitly define or constrain the hypothesis space $\\mathcal{H}$. The structure of $f^{*}$ is unknown ‚Äî and likely inexpressible in closed-form. Instead, we turn to flexible, expressive models capable of approximating a wide range of functions. This is the motivator for architectures such as neural networks which we'll begin to explore in the next workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa7c0b",
   "metadata": {},
   "source": [
    "This leads to a fundamental source of error in machine learning, approximation error $\\epsilon_{approx}$. Approximation error represents the error between the best function we can express in the hypothesis space $f^{*}_{\\mathcal{H}}$ and the target function $f^{*}$:\n",
    "\n",
    "\\begin{align*}\n",
    "    f^{*}_{\\mathcal{H}} = argmin_{f \\in \\mathcal{H}}\\mathcal{L}(f,f^{*}) \\tag{1.12}\n",
    "\\end{align*}\n",
    "\n",
    "Thus, we want to design $\\mathcal{H}$ such that it can express $f^{*}$ as closely as possible, ideally $\\mathcal{H} \\subseteq \\mathcal{T}$.\n",
    "\n",
    "üí¨ *Question for the audience! Does your task have an approximation error, can you perfectly represent your target function within your hypothesis space?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d701c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52883b",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    üìâ Section 2. How do we select the best parameters?\n",
    "</h2>\n",
    "\n",
    "So to summarize where we're at. \n",
    "1. We have some function $f^{*}$ we want to approximate.\n",
    "2. We've design a set of functions $f_{\\theta} \\in \\mathcal{H}$ we hypothesize may be suitable solutions which are parameterized by $\\theta \\in \\Theta$.\n",
    "\n",
    "Our next question is how do we select a parameterization $\\theta \\in \\Theta$ and then determine whether this is suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1f790",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Section 2A. Selecting a model from the hypothesis space.\n",
    "</h3>\n",
    "\n",
    "Continuing to use our example function, we have some target function $f^{*}$ that represents a data generating process, it is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "    f^*(x) = e^{-x^{2}} \\cdot \\sin(5.8 \\pi x + 0.41), \\quad \\text{for } x \\in [0, 1] \\tag{2.1}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c6a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target function\n",
    "def f_target(x):\n",
    "    return np.exp(-x**2) * np.sin(5.8 * np.pi * x + 0.41)\n",
    "\n",
    "# suppose we can observe the target function perfectly (not just evaluate it)\n",
    "N = 1000\n",
    "x = np.linspace(0, 1, num=N)\n",
    "y = f_target(x)\n",
    "\n",
    "# plot the target function\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.plot(x, y, label=\"target\")\n",
    "ax.set_xlim(x.min(), x.max())\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"f(x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1e022",
   "metadata": {},
   "source": [
    "Let's define a hypothesis space (the structure) of our function and select a single function from this space using a specific set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947facf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your hypothesis space\n",
    "def H(tau, phi):\n",
    "    def f(x):\n",
    "        return np.exp(-x**2) * np.sin(tau * np.pi * x + phi) # <-- TODO: this is probably a poor hypothesis - have a go at re-writing it\n",
    "    return f\n",
    "\n",
    "# select a function from this space\n",
    "f_approx = H(tau=2, phi=-0.5) # <-- TODO: these is probably a poor parameterization - pick some better parameters\n",
    "\n",
    "# make predictions\n",
    "y_pred = f_approx(x)\n",
    "\n",
    "# plot the target function\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.plot(x, y, label=\"target (f*)\")\n",
    "ax.plot(x, y_pred, label=\"approx (f)\")\n",
    "ax.set_xlim(x.min(), x.max())\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"f(x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269cc863",
   "metadata": {},
   "source": [
    "Obviously in this scenario we can perfectly observe the function and see it's form - in this scenario it's quite easy to select the right hypothesis space and then pick a good parameterization. Let's put this into a more realistic perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f7765",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    üîç Section 2B. Observing the Data Generating Processes\n",
    "</h2>\n",
    "\n",
    "While we may not known the function $f^{*}$, we can often observe its behaviour. That is, we can collect a set of data $\\mathcal{D}$ generated by the processes governing this function - usually in the form of input/output pairs $(\\mathcal{X}_{i}, \\mathcal{Y}_{i})$:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{D} = \\left\\{ (\\mathcal{X}_{i}, \\mathcal{Y}_{i}) \\right\\}_{i=0}^{N} \\tag{2.2}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $\\mathcal{X}_{i}$ represents an observation of the input.\n",
    "- $\\mathcal{Y}_{i}$ represents an observation of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e6670",
   "metadata": {},
   "source": [
    "Observing both the input and output sides of a data generating process is often a messy, uncertain, and biased process ‚Äî filled with various sources of noise, systematic errors, and missing information. For the example of weather forecasting, we might have to aggregate, process, and measurements from various sources - satellites, weather stations, aircraft - to try and get a sample of the \"current state of the atmosphere\".\n",
    "\n",
    "- $\\mathcal{X}_i$ represents the observed current or historical atmospheric state, assembled from multiple noisy sensors.\n",
    "- $\\mathcal{Y}_i$ represents the future state we hope to predict ‚Äî often inferred from models, simulations, or delayed ground-truth verification.\n",
    "\n",
    "Even with sophisticated tools, observations are rarely complete, consistent, or unbiased. Noise and bias in data don‚Äôt just affect accuracy ‚Äî they shape what kind of function we‚Äôre able to learn. Understanding the imperfections in your data is just as important as designing your model.\n",
    "\n",
    "üí¨ *Question for the audience!*\n",
    "*1. What is your input data? How is it sampled? What errors exist in the measurement process?*\n",
    "*2. What is your output data? How is it sampled? What errors exist in the measurement process?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44378b",
   "metadata": {},
   "source": [
    "For example, we aim to observe our target function $f^{*}$, however there might be errors in where we measure $x + \\epsilon_{x}$ and the observerations $y + \\epsilon_{y}$.\n",
    "\n",
    "\\begin{align*}\n",
    "    f^*(x) = e^{-x^{2}} \\cdot \\sin(5.8 \\pi x + 0.41), \\quad \\text{for } x \\in [0, 1] \\tag{2.3}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect observation process\n",
    "def observe_perfect(f, x):\n",
    "    return f(x)\n",
    "\n",
    "# for refernce\n",
    "N = 1000\n",
    "x = np.linspace(0, 1, num=N)\n",
    "y = observe_perfect(f_target, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20bde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise observation process\n",
    "def observe_noisy(f, x):\n",
    "    # we often can't sample perfectly a point in the domain perfectly\n",
    "    x_noise = np.random.normal(0.15, 0.05, x.shape[0])\n",
    "    x_measure = x + x_noise\n",
    "\n",
    "    # we often can't measure the result perfectly\n",
    "    y_noise = np.random.normal(-0.13, 0.16, x.shape[0])\n",
    "    y_obs = f(x_measure) + y_noise\n",
    "\n",
    "    return y_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a set of points we want to observe the function\n",
    "x_meas = np.random.rand((10))\n",
    "\n",
    "# noisily observe the function\n",
    "y_obs = observe_noisy(f_target, x_meas)\n",
    "\n",
    "# plot the results\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "# ax.plot(x, y, label=\"target\", alpha=0.25) # <-- feel free to uncomment\n",
    "ax.scatter(x_meas, y_obs, s=6, label=\"observations\")\n",
    "ax.set_xlim(x_meas.min(), x_meas.max())\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"x (where we think we sampled)\")\n",
    "ax.set_ylabel(\"y (observed response)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb409d3d",
   "metadata": {},
   "source": [
    "Assuming we don‚Äôt have access to the true function $f^{*}$, it can be extremely difficult to form a hypothesis about what kind of function might have generated a dataset ‚Äî especially when the observations are sparse. From a visual standpoint, attempting to fit a curve through a handful of points can lead to wildly different interpretations depending on the assumptions we make. Lets try to sample the dataset more densely and potentially more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise observation process <-- improve this\n",
    "def observe_noisy(f, x):\n",
    "    # we often can't sample perfectly a point in the domain perfectly\n",
    "    x_noise = np.random.normal(0.15, 0.01, x.shape[0]) # <-- vary the mean/std and see what happens\n",
    "    x_measure = x + x_noise\n",
    "\n",
    "    # we often can't measure the result perfectly\n",
    "    y_noise = np.random.normal(-0.13, 0.16, x.shape[0]) # <-- vary the mean/std of the observation noise and see what happens\n",
    "    y_obs = f(x_measure) + y_noise\n",
    "\n",
    "    return y_obs\n",
    "\n",
    "# define a set of points we want to observe the function\n",
    "x_meas = np.array([0.1, 0.15, 0.3, 0.5, 0.7, 0.72, 0.8, 0.84]) # <-- explore some different measurement points and potentially more\n",
    "y_obs = observe_noisy(f_target, x_meas)\n",
    "\n",
    "# plot the results\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.scatter(x_meas, y_obs, s=6, label=\"observations\")\n",
    "ax.set_xlim(x_meas.min(), x_meas.max())\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786086ca",
   "metadata": {},
   "source": [
    "Each observation provides a constraint on the behaviour of the function $f^{*}$ at a specific point in the input space $\\mathcal{X}$, by revealing what output it maps to $\\mathcal{Y}$. Collectively the dataset $\\mathcal{D}$ constrains the parameters of our model $f_{\\theta}$. We might find no suitable parameters fit our data well - we would then need to go back designing a more suitable hypothesis space $\\mathcal{H}$.\n",
    "\n",
    "See if you can find a good parameterization purely based on the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64804c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a suitable parameterization \n",
    "f_approx = H(tau=1, phi=1) # <-- vary the parameterization\n",
    "\n",
    "# get our predictions\n",
    "y_pred = f_approx(x_meas)\n",
    "\n",
    "# plot the target function\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.scatter(x_meas, y_obs, s=6, label=\"target\")\n",
    "ax.scatter(x_meas, y_pred, s=6, label=\"predicted\")\n",
    "ax.set_xlim(x_meas.min(), x_meas.max())\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1338e1c8",
   "metadata": {},
   "source": [
    "As you're going through this manual optimization process it's good to notice that you're relying on your observations $\\mathcal{D}$ to constrain $f_{\\theta}$ - this is more or less the process of learning - constraining your model using evidence. This forces us to ask whether $\\mathcal{D}$ is sufficient to capture and accurately represent the relevant features of $f^{*}$. This discussion on how sufficiently and accurately we resolve the data manifold is a crucial aspect of machine learning - in approximation theory e.g. polynomial interpolation, error bounds of the function approximation often depend on the maximum spacing between samples:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\epsilon \\propto \\delta^{k} \\cdot || f^{(k)} ||_{\\infty}, \\quad \n",
    "    \\delta = max_{i}(\\mathcal{X}_{i+1} - \\mathcal{X}_{i}) \\tag{2.4}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $\\epsilon$ is the error bound\n",
    "- $f^{(k)}$ is the $k$-th derivative of a function $f$\n",
    "- $\\delta$ is the largest distance between points\n",
    "\n",
    "Where a functions value changes rapidly (high $f^{(k)}$) to make sure we can constrain our function (minimize $\\epsilon$) we need to sample the points more densely around this area of change (minimize $\\delta$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fefine a domain and anchor points\n",
    "x = np.linspace(-1, 1, 200)\n",
    "x2 = np.array([-0.5, 0.5])\n",
    "y2 = np.array([0.0, 1.0])\n",
    "\n",
    "# generate a set of functions that fit exactly through the 2 points\n",
    "functions_2pts = []\n",
    "for _ in range(20):\n",
    "    coeffs = np.random.randn(6)\n",
    "    A = np.vstack([x2**i for i in range(6)]).T\n",
    "    correction = np.linalg.lstsq(A, y2, rcond=None)[0]\n",
    "    coeffs[:2] = correction[:2]\n",
    "    functions_2pts.append(np.poly1d(coeffs[::-1]))\n",
    "\n",
    "# add a third point\n",
    "x3 = np.append(x2, [0.0])\n",
    "y3 = np.append(y2, [3.0])  # raise the third point significantly\n",
    "\n",
    "# generate functions that fit all 3 points\n",
    "functions_3pts_high = []\n",
    "for _ in range(20):\n",
    "    coeffs = np.random.randn(6)\n",
    "    A = np.vstack([x3**i for i in range(6)]).T\n",
    "    correction = np.linalg.lstsq(A, y3, rcond=None)[0]\n",
    "    coeffs[:3] = correction[:3]\n",
    "    functions_3pts_high.append(np.poly1d(coeffs[::-1]))\n",
    "\n",
    "# plot the functions\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 3), sharey=True)\n",
    "\n",
    "# plot functions through 2 points\n",
    "axs[0].set_title(\"Functions Passing Through 2 Points\")\n",
    "for f in functions_2pts:\n",
    "    axs[0].plot(x, f(x), color='gray', alpha=0.5)\n",
    "axs[0].scatter(x2, y2, color='red', label='Anchor Points')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# plot functions through 3 points (with raised 3rd point)\n",
    "axs[1].set_title(\"Functions Constrained by Raised 3rd Point\")\n",
    "for f in functions_3pts_high:\n",
    "    axs[1].plot(x, f(x), color='blue', alpha=0.5)\n",
    "axs[1].scatter(x3, y3, color='red', label='Anchor Points')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.suptitle(\"Data constrains the functions we can learn.\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064eb041",
   "metadata": {},
   "source": [
    "We can see that data is required to resolve the behaviour of the target function $f^{*}$ and ensure suitable interpolation - this is what it means to generalize - to accurately interpolate and extrapolate to points not in your training distribution.\n",
    "\n",
    "üí¨ *Question for the audience! Does your dataset accurately reflect your target function? A good way to interrogate this is by considering where your model performs poorly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106c538e",
   "metadata": {},
   "source": [
    "However, this process of fitting functions by hand isn't a particularly rigorous approach - what does it mean for your parameterization to be a good fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522dbec",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    üéØ Section 2C. Evaluating the fit of our function\n",
    "</h3>\n",
    "\n",
    "We need a way to measure how well our function $f_{\\theta}$ performs compared to $f^{*}$ to guide our parameterization $\\theta \\in \\Theta$ - we don't have access to $f^{*}$ directly. However, we do have observations of $f^{*}$ as represented by $\\mathcal{D}$. We can instead compare how well our function $f$ evaluated at a point $\\mathcal{X}_{i}$ predicts the observations $\\mathcal{Y}_{i}$.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\hat{\\mathcal{Y}}_i = f_\\theta(\\mathcal{X}_i) \\tag{2.6}\n",
    "\\end{align*}\n",
    "\n",
    "By comparing $\\hat{\\mathcal{Y}}_i$ with the observations $\\mathcal{Y}_{i}$ we can compute an empirical approximation of the true error as defined by the observations:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{L}(\\mathcal{D}, f_\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} \\ell\\left(\\hat{y}_{i}, y_i\\right) = \\frac{1}{n} \\sum_{i=1}^{n} \\ell\\left(f_\\theta(x_i), y_i\\right) \\tag{2.7}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $\\ell(\\cdot, \\cdot)$ is a pointwise loss function, such as the mean squared error $(\\hat{\\mathcal{Y}}_i - \\mathcal{Y}_{i})^{2}$\n",
    "- $\\mathcal{L}$ is the average loss over the dataset $\\mathcal{D}$.\n",
    "\n",
    "This loss value $\\mathcal{L}$ provides feedback about how good our parameterization $f_{\\theta}$ is, based on the evidence $\\mathcal{D}$. There are numerous ways to define the pointwise loss function $\\ell$, each reflecting different assumptions, goals, or properties of the task and this also has implications for the learning process as we'll see. Lets see how we could implement an example below:\n",
    "\n",
    "üí¨ *Question for the audience! What loss functions have you used before? Have you used a different loss function and seen a significant difference in model behaviour?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4097d3",
   "metadata": {},
   "source": [
    "1. Lets first define the pointwise loss $\\ell(\\cdot, \\cdot)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"f_approx({x_meas[0]}) = {f_approx(x_meas[0]):.2f}\")\n",
    "print(f\"f_target({x_meas[0]}) = {y_obs[0]:.2f}\")\n",
    "\n",
    "print(f\"distance between {f_approx(x_meas[0]):.2f} and {y_obs[0]:.2f} = ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a67131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define a pointwise loss function\n",
    "def pointwise_mse_loss(y, y_hat):\n",
    "    \"\"\"\n",
    "    mean squared error (MSE)\n",
    "    \"\"\"\n",
    "    return (y_hat - y) ** 2\n",
    "\n",
    "L = pointwise_mse_loss(y_obs[0], f_approx(x_meas[0]))\n",
    "print(f\"mse loss between target {y_obs[0]:.2f} and predicted {f_approx(x_meas[0]):.2f} is {L:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce9629",
   "metadata": {},
   "source": [
    "2. We can then compute the average loss across the entire dataset $\\frac{1}{n} \\sum_{i=1}^{n} \\ell\\left(f_\\theta(x_i), y_i\\right)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define a function that computes the average loss across a dataset\n",
    "def compute_dataset_loss(f, x, y, loss_fn):\n",
    "    # compute predictions\n",
    "    y_hat = f(x)\n",
    "\n",
    "    # number of samples\n",
    "    N = y.shape[0]\n",
    "\n",
    "    # accumulate loss across samples\n",
    "    L = 0\n",
    "    for i in range(N):\n",
    "        L += loss_fn(y[i], y_hat[i])\n",
    "\n",
    "    # compute average loss\n",
    "    L = (1/N) * L\n",
    "\n",
    "    return float(L)\n",
    "\n",
    "# lets compute the average mse loss across the dataset for our function\n",
    "L_D = compute_dataset_loss(f_approx, x_meas, y_obs, pointwise_mse_loss)\n",
    "print(f\"L_D = {L_D:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c4db4",
   "metadata": {},
   "source": [
    "<h3>üèûÔ∏è Section 2D. The Loss Landscape</h3>\n",
    "\n",
    "We can now empirically compute how well our model $f_{\\theta}$ fits the dataset $\\mathcal{D}$ using through $\\mathcal{L}(\\mathcal{D}, f_\\theta)$. Crucially, we observe that the loss function $\\mathcal{L}(\\mathcal{D}, f_\\theta)$ is a function over the data and parameter space. We can see that a given dataset will restrict the set of parameters we can learn - in essense the evidence contained in the dataset restricts the subset of hypothesis space we can learn.\n",
    "\n",
    "This leads to a fundamental source of error in machine learning - generalization error $\\epsilon_{gen}$. The generalization error represents the error between the best possible function constricted by the hypothesis space and dataset $\\hat{f}$ and the target function $f^{*}$. Formally, we define the empirical-risk minimiser $\\hat{f}$ as the function in our hypothesis space $\\mathcal{H}$ that best fits the training data $\\mathcal{D}$:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\hat{f} = \\text{argmin}_{f_{\\theta} \\in \\mathcal{H}} \\mathcal{L}(\\mathcal{D}, f_\\theta) \\tag{2.8}\n",
    "\\end{align*}\n",
    "\n",
    "üí¨ *Question for the audience: How well does your dataset represent the target function - what aspects does it not capture properly - does this limit generalization?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1dc57",
   "metadata": {},
   "source": [
    "For a given dataset $\\mathcal{D}$ we can view the loss function as a function of the parameters of our function.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{L}(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} ((e^{-x^{2}} \\cdot \\sin(2 \\pi \\theta_{0} x + \\theta_{1})) - y_i)^{2} \\tag{2.9}\n",
    "\\end{align*}\n",
    "\n",
    "Let's explore how the loss value varies with the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce119e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets consider a single parameter\n",
    "theta_0 = np.linspace(-5, 5, num=1000) # <-- is this a suitable range for the parameter?\n",
    "theta_1 = 0.41\n",
    "\n",
    "# lets compute the loss (error across the dataset) for each function defined by the parameter\n",
    "losses = np.zeros_like(theta_0)\n",
    "for i in range(theta_0.shape[0]):\n",
    "    # select a function from the hypothesis space - each point in parameter space is a function\n",
    "    f_approx = H(tau=theta_0[i], phi=theta_1)\n",
    "\n",
    "    # perform predictions based on dataset\n",
    "    y_pred = f_approx(x_meas)\n",
    "\n",
    "    # compute loss across dataset\n",
    "    losses[i] = compute_dataset_loss(f_approx, x_meas, y_obs, pointwise_mse_loss)\n",
    "\n",
    "# lets plot the result\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.plot(theta_0, losses)\n",
    "ax.set_xlim(theta_0.min(), theta_0.max())\n",
    "ax.set_xlabel(\"theta_0\")\n",
    "ax.set_ylabel(\"Dataset Loss (MSE)\")\n",
    "ax.set_title(f\"Loss Landscape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a63057",
   "metadata": {},
   "source": [
    "We know the actual parameters of the function are given by:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\theta_{0} = 5.8, \\quad \\theta_{1} = 0.41\n",
    "\\end{align*}\n",
    "\n",
    "So how well does this align with our expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a77d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is it minimum?\n",
    "min_idx = np.argmin(losses)\n",
    "print(f\"minimum loss L={losses[min_idx]:.3f} occurs at theta_0={theta_0[min_idx]:.3f} for theta_1={theta_1}\")\n",
    "\n",
    "# lets see what this parameterization looks like\n",
    "f_approx = H(tau=theta_0[min_idx], phi=theta_1)\n",
    "y_pred = f_approx(x_meas)\n",
    "\n",
    "# plot the target function\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.scatter(x_meas, y_obs, s=6, label=\"target\")\n",
    "ax.scatter(x_meas, y_pred, s=6, label=\"predicted\")\n",
    "ax.set_xlim(x_meas.min(), x_meas.max())\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "# share your results in the chat!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14043e99",
   "metadata": {},
   "source": [
    "We can see thaty we've fit the training distribution well, however didn't we expect to obtain $\\theta_{0} = 5.8$? If we were careful we might notice there is a systematic bias in how we've collected the data which has significantly changed the function we measure and thus what we can learn. Or we might have found a different solution given the periodicity of this function. Post your plots in the chat and we can discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96259049",
   "metadata": {},
   "source": [
    "Okay, to find this \"best\" $\\theta_{0}$ we had to assume a well-known $\\theta_{1}$. Lets relax this assumption by extending th visualization of the loss landscape to two dimensions and see how it varies as a function of both parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408fc9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets consider a single parameter\n",
    "theta_0 = np.linspace(-2, 2, num=100) # <-- explore a different range, does [-5,5] let you find the optimal solution?\n",
    "theta_1 = np.linspace(-2, 2, num=100)\n",
    "T0, T1 = np.meshgrid(theta_0, theta_1, indexing=\"ij\")\n",
    "\n",
    "# lets compute the loss (error across the dataset) for each function defined by the parameter\n",
    "losses = np.zeros_like(T0)\n",
    "for i in range(T0.shape[0]):\n",
    "    for j in range(T1.shape[0]):\n",
    "        # select a function from the hypothesis space\n",
    "        f_approx = H(tau=T0[i,j], phi=T1[i,j])\n",
    "\n",
    "        # compute loss across dataset\n",
    "        losses[i,j] = compute_dataset_loss(f_approx, x_meas, y_obs, pointwise_mse_loss)\n",
    "        \n",
    "\n",
    "# lets plot the result\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "s = ax.plot_surface(T0, T1, losses, cmap='viridis')\n",
    "ax.set_xlim(theta_0.min(), theta_0.max())\n",
    "ax.set_ylim(theta_1.min(), theta_1.max())\n",
    "ax.set_xlabel(\"theta_0 (tau)\")\n",
    "ax.set_ylabel(\"theta_1 (phi)\")\n",
    "ax.set_zlabel(\"Dataset Loss (MSE)\")\n",
    "ax.set_title(f\"Loss Landscape\")\n",
    "\n",
    "# as a contour plot\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "contour = ax.contourf(T0, T1, losses, levels=50, cmap='viridis')\n",
    "ax.set_xlim(theta_0.min(), theta_0.max())\n",
    "ax.set_ylim(theta_1.min(), theta_1.max())\n",
    "ax.set_xlabel(\"theta_0 (tau)\")\n",
    "ax.set_ylabel(\"theta_1 (phi)\")\n",
    "ax.set_title(f\"Loss Landscape (Top-down View)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb4e60",
   "metadata": {},
   "source": [
    "Please post your loss landscape in the chat? How does it vary as you vary the dataset? What about the loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is it minimum?\n",
    "t0_min_idx, t1_min_idx = np.unravel_index(np.argmin(losses), losses.shape)\n",
    "print(f\"minimum loss L={losses[t0_min_idx,t1_min_idx]:.3f} occurs at theta_0={theta_0[t0_min_idx]:.3f} for theta_1={theta_1[t1_min_idx]:.3f}\")\n",
    "\n",
    "# lets see what this parameterization looks like\n",
    "f_approx = H(tau=theta_0[t0_min_idx], phi=theta_1[t1_min_idx])\n",
    "y_pred = f_approx(x_meas)\n",
    "\n",
    "# plot the target function\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.scatter(x_meas, y_obs, s=6, label=\"target\")\n",
    "ax.scatter(x_meas, y_pred, s=6, label=\"predicted\")\n",
    "ax.set_xlim(x_meas.min(), x_meas.max())\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2ba90",
   "metadata": {},
   "source": [
    "We can view our function as being at a specific point in this space defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a contour plot\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "contour = ax.contourf(T0, T1, losses, levels=50, cmap='viridis')\n",
    "ax.set_xlim(theta_0.min(), theta_0.max())\n",
    "ax.set_ylim(theta_1.min(), theta_1.max())\n",
    "ax.set_xlabel(\"theta_0 (tau)\")\n",
    "ax.set_ylabel(\"theta_1 (phi)\")\n",
    "ax.set_title(f\"Loss Landscape (Top-down View)\")\n",
    "\n",
    "# plot our function in parameter space\n",
    "tau=theta_0[t0_min_idx]\n",
    "phi=theta_1[t1_min_idx]\n",
    "ax.scatter(tau, phi, s=64, marker=\"x\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66764c",
   "metadata": {},
   "source": [
    "While we can't properly visualize spaces with more than three dimensions in our universe - viewing the loss landscape as a geometric surface is a powerful way to think about learning. Low points (minima) represent good solutions (low loss) and high points (maxima) represent poor solutions (high loss). The loss landscape is a geometric object that encodes the structure of the learning problem - linking together the dataset, model, and eventually the optimization procedure. Understanding its shape helps us reason about trainability, sensitivty of the model to initialization, and the nature of solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b160140c",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    Section 3. Optimization - The Learning in Machine Learing \n",
    "</h2>\n",
    "\n",
    "So to summarize where we're at:\n",
    "1. We have chosen a hypothesis space $\\mathcal{H}$.\n",
    "2. We have collected a dataset $\\mathcal{D}$.\n",
    "3. We have defined a loss function $\\mathcal{L}(f_\\theta(x), \\mathcal{D})$ that we can visualize to find a good solution.\n",
    "\n",
    "We're viewing this as an optimization problems where we're aiming to explore $\\mathcal{H}$ - varying $\\theta$ to minimize $\\mathcal{L}(f_\\theta(x), \\mathcal{D})$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\theta^* = \\arg\\min_\\theta \\mathcal{L}(f_\\theta(x), y) \\tag{3.1}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "So what happens when the loss landscape becomes higher dimensional and we can visualize it? What if it's simply too computationally costly to evaluate the loss landscape? We need a better way to navigate this landscape. While there are lots of different techniques to perform optimization such as evolutionary algorithms - it turns out our best current approach is to blindly feel our way across the surface - this process is called gradient descent.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/nextgenerationgraduatesprogram/nextgen25-mlai-workshop01/raw/main/media/notebook/GradientDescent.png\" height=\"400\"/>\n",
    "    <p><em>Figure 4. Gradient descent is an optimization algorithm used to iteratively adjust model parameters in the direction that most reduces the loss function.\n",
    " </em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7e2c7",
   "metadata": {},
   "source": [
    "<h3>Section 3A. Gradient Descent</h3>\n",
    "\n",
    "Gradient descent is one of the most widely used optimization algorithms in machine learning. Gradient descent is an iterative method that uses the gradient (a vector indicating the slope of the loss surface at a point) to determine the direction of steepest descent, and updates model parameters in the direction to minimize the loss:\n",
    "\n",
    "\\begin{align*}\n",
    "\\theta := \\theta - \\eta \\cdot \\nabla_\\theta \\mathcal{L}(f_\\theta(x), y) \\tag{3.2}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $\\nabla_\\theta \\mathcal{L}$ is the gradient of the loss w.r.t. parameters.\n",
    "- $\\eta$ is the learning rate - the size of our step.\n",
    "\n",
    "Imagine standing blindfolded in a mountainous landscape ‚Äî this is your loss landscape. You can‚Äôt see the terrain, but you‚Äôre trying to reach the lowest valley (the global minimum). To do this, you feel the slope around your feet ‚Äî this is like computing the local gradient. Based on this local information, you take a small step downhill. Then you repeat: feel, step, repeat. That‚Äôs gradient descent ‚Äî a blind but guided walk through parameter space, steadily improving the model with each step.\n",
    "\n",
    "So how do we compute and apply the gradient? Calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd2696d",
   "metadata": {},
   "source": [
    "Our loss function is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta) \n",
    "= \\frac{1}{n} \\sum_{i=1}^{n} \\left( f_\\theta(x_i) - y_i \\right)^2  \\tag{3.2}\n",
    "\\end{align*}\n",
    "\n",
    "Our goal is to compute the gradient in the direction of each parameter (direction on the loss landscape):\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_\\theta \\mathcal{L}(\\theta) = (\\frac{\\partial \\mathcal{L}}{\\partial \\theta_0}, \\frac{\\partial \\mathcal{L}}{\\partial \\theta_1}) \\tag{3.4}\n",
    "\\end{align*}\n",
    "\n",
    "The chain rule allows us to decompose the loss derivative into the product of:\n",
    "- The derivative of the loss with respect to the model output (error),\n",
    "- And the derivative of the model output with respect to the parameter.\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\theta_0} \n",
    "= \\frac{\\partial \\mathcal{L}}{\\partial f_\\theta(x_i)} \\cdot \\frac{\\partial f_\\theta(x_i)}{\\partial \\theta_0} \n",
    "= \\frac{1}{n} \\sum 2(f_\\theta(x_i) - y_i) \\cdot \\frac{\\partial f_\\theta(x_i)}{\\partial \\theta_0} \\tag{3.6}\n",
    "\\end{align*}\n",
    "\n",
    "We can then differentiate the model function with respect to $\\theta_0$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial f_\\theta(x_i)}{\\partial \\theta_0}\n",
    "= \\frac{\\partial}{\\partial \\theta_0} \\left[ e^{-x_i^2} \\cdot \\sin(\\theta_0 \\pi x_i + \\theta_1) \\right]\n",
    "= e^{-x_i^2} \\cdot \\cos(\\theta_0 \\pi x_i + \\theta_1) \\cdot \\pi x_i \\tag{3.7}\n",
    "\\end{align*}\n",
    "\n",
    "Putting it all together:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\theta_0}\n",
    "= \\frac{2}{n} \\sum (f_\\theta(x_i) - y_i) \\cdot e^{-x_i^2} \\cdot \\cos(\\theta_0 \\pi x_i + \\varphi) \\cdot \\pi x_i \\tag{3.8}\n",
    "\\end{align*}\n",
    "\n",
    "Then we repeat the same process for every single parameter in our model. This lets us efficiently compute how changes in parameters influence the overall loss, and is the mechanism used in frameworks like PyTorch and TensorFlow during automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f866cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can compute the derivatives of our function\n",
    "def df_dtau(x, tau, phi):\n",
    "    return 2 * np.pi * x * np.exp(-x**2) * np.cos(2 * np.pi * tau * x + phi)\n",
    "\n",
    "def df_dphi(x, tau, phi):\n",
    "    return np.exp(-x**2) * np.cos(2 * np.pi * tau * x + phi)\n",
    "\n",
    "\n",
    "# and compute the derivative of the loss wrt to our function\n",
    "def grad_mse_tau_phi(x, y, tau, phi):\n",
    "    y_pred = H(tau, phi)(x)\n",
    "    error = y_pred - y\n",
    "\n",
    "    dL_dtau = 2 * np.mean(error * df_dtau(x, tau, phi))\n",
    "    dL_dphi = 2 * np.mean(error * df_dphi(x, tau, phi))\n",
    "\n",
    "    return dL_dtau, dL_dphi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets setup a grid of parameters\n",
    "theta_0 = np.linspace(-2, 2, num=100)  # <-- explore a different range of parameter values ; trade-off of coverage vs. resolution\n",
    "theta_1 = np.linspace(-2, 2, num=100) \n",
    "T0, T1 = np.meshgrid(theta_0, theta_1, indexing=\"ij\")\n",
    "\n",
    "# lets compute the loss at each point of the grid (for visualization)\n",
    "losses = np.zeros_like(T0)\n",
    "for i in range(T0.shape[0]):\n",
    "    for j in range(T0.shape[1]):\n",
    "        _f = H(tau=T0[i, j], phi=T1[i, j])\n",
    "        losses[i, j] = compute_dataset_loss(_f, x_meas, y_obs, pointwise_mse_loss)\n",
    "\n",
    "# 1. define the parameter values\n",
    "tau, phi = 0., 0. # <-- explore different points in the landscape and see how the gradient varies\n",
    "\n",
    "# 2. compute the gradient of the loss with respect to each parameter - \\nalba_{theta}\n",
    "dL_dtau, dL_dphi = grad_mse_tau_phi(x_meas, y_obs, tau, phi)\n",
    "\n",
    "# 3.  scale the gradient by a step size\n",
    "lr = 1.00\n",
    "dL_dtau = -lr * dL_dtau\n",
    "dL_dphi = -lr * dL_dphi\n",
    "\n",
    "# plot contour and gradient vector\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "contour = ax.contourf(T0, T1, losses, levels=50, cmap='viridis')\n",
    "ax.set_xlim(T0.min(), T0.max())\n",
    "ax.set_ylim(T1.min(), T1.max())\n",
    "ax.set_xlabel(\"tau\")\n",
    "ax.set_ylabel(\"phi\")\n",
    "ax.set_title(\"Loss Landscape with Gradient Vector\")\n",
    "ax.quiver(tau, phi, dL_dtau, dL_dphi, angles='xy', scale_units='xy', scale=1, color='red', width=0.01)\n",
    "ax.plot(tau, phi, 'ro', label=\"Start Point\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aedcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_traj(tau_init, phi_init, x, y, lr, steps):\n",
    "    tau, phi = tau_init, phi_init\n",
    "    history = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        # define model and compute error\n",
    "        f_approx = H(tau, phi)\n",
    "        y_pred = f_approx(x)\n",
    "        error = y_pred - y\n",
    "\n",
    "        # compute gradients using known partial derivatives\n",
    "        grad_tau = 2 * np.mean(error * df_dtau(x, tau, phi))\n",
    "        grad_phi = 2 * np.mean(error * df_dphi(x, tau, phi))\n",
    "\n",
    "        # store history before update\n",
    "        loss = np.mean((y - y_pred)**2)\n",
    "        history.append((tau, phi, loss))\n",
    "\n",
    "        # gradient descent update\n",
    "        tau -= lr * grad_tau\n",
    "        phi -= lr * grad_phi\n",
    "\n",
    "    return np.array(history)\n",
    "\n",
    "# Run gradient descent\n",
    "trajectory = gradient_descent_traj(tau_init=.0, phi_init=.0, x=x_meas, y=y_obs, lr=1.00, steps=10) # <-- vary the initial point, the learning rate, and the step size : how do these impact the solution you find?\n",
    "\n",
    "# Plot loss over iterations\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.plot(trajectory[:, 2], label=\"Loss over Iterations\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Loss (MSE)\")\n",
    "ax.set_title(\"Loss Curve\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "# Plot the path on the loss landscape\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "contour = ax.contourf(T0, T1, losses, levels=50, cmap='viridis')\n",
    "ax.set_xlim(T0.min(), T0.max())\n",
    "ax.set_ylim(T1.min(), T1.max())\n",
    "ax.set_xlabel(\"tau\")\n",
    "ax.set_ylabel(\"phi\")\n",
    "ax.set_title(\"Gradient Descent Path on Loss Landscape\")\n",
    "\n",
    "# Path\n",
    "ax.plot(trajectory[0, 0], trajectory[0, 1], 'rx', label=\"Initial Point\")\n",
    "ax.plot(trajectory[:, 0], trajectory[:, 1], 'r-', alpha=0.25, label=\"Gradient Descent Path\")\n",
    "ax.plot(trajectory[-1, 0], trajectory[-1, 1], 'ro', label=\"Final Point\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9577f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized model\n",
    "final_tau, final_phi = tuple(trajectory[-1,:2].tolist())\n",
    "f_tilde = H(final_tau, final_phi)\n",
    "print(f\"our optimized model f_tilde has theta0={final_tau:.3f} and theta1={final_phi:.3f}\")\n",
    "\n",
    "# lets visualize it\n",
    "y_pred = f_tilde(x_meas)\n",
    "\n",
    "# plot the target function\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.scatter(x_meas, y_obs, s=6, label=\"target\")\n",
    "ax.scatter(x_meas, y_pred, s=6, label=\"predicted\")\n",
    "ax.set_xlim(x_meas.min(), x_meas.max())\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cbd007",
   "metadata": {},
   "source": [
    "We refer to the model with the set of parameters determined by the optimization process as $\\tilde{f}$.\n",
    "\n",
    "This leads to another fundamental source of error in machine learning, the optimization error, $\\epsilon_{opt}$. The optimization error error represents the error between $\\hat{f}$ (best possible model your hypothesis space could express based on the data) and $\\tilde{f}$ (the model your optimization algorithm actually found), in essense the error as a result of the imperfect optimization process. Even when the hypothesis space $\\mathcal{H}$ is expressive enough to represent a good approximation of the true function, you may not reach that optimum during training. This happens due to:\n",
    "- Poor initialization: Your starting point in parameter space may be far from the optimum.\n",
    "- Learning rate issues: If your learning rate is too high, you may overshoot the minimum. If too low, training may stagnate.\n",
    "- Early stopping: Optimization may be halted before convergence due to computational limits or regularization strategies.\n",
    "- Local minima or saddle points: In non-convex landscapes, the optimizer may get trapped in regions that are suboptimal.\n",
    "- Noisy or stochastic gradients: In mini-batch training, variance in gradient estimates can lead to imperfect updates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760f668",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508391a",
   "metadata": {},
   "source": [
    "<h2>üß† Workshop Summary: What Have We Learned?</h2>\n",
    "\n",
    "Over the course of this workshop, we‚Äôve taken a step back from just \"using machine learning models\" and instead focused on building a deeper understanding of how learning works ‚Äî and why. Whilst this first workshop was very theory heavy - we're going to revisit and reinforce some of these concepts throughout the next set of workshops - hopefully this provides some good intuition for the future.\n",
    "\n",
    "\n",
    "<h3>üîÅ 1. Machine Learning is About Learning Functions</h3>\n",
    "\n",
    "We reframed machine learning as the task of approximate an unknown function $f^*$ that maps inputs to outputs:\n",
    "\\begin{align*}\n",
    "    f^*: \\mathcal{X} \\rightarrow \\mathcal{Y}\n",
    "\\end{align*}\n",
    "\n",
    "Since we rarely know $f^*$ directly, we observe data $\\mathcal{D}$ ‚Äî noisy samples of its behavior ‚Äî and attempt to learn an approximation $f_\\theta$ that generalizes well.\n",
    "\n",
    "<h3>üìê 2. We Define a Hypothesis Space</h3>\n",
    "\n",
    "We choose a hypothesis space $\\mathcal{H}$: the family of functions we‚Äôre willing to consider. This reflects our assumptions and modeling choices ‚Äî linear functions, neural nets, polynomials, etc.\n",
    "\n",
    "\n",
    "<h3>üéØ 3. We Use Data to Constrain the Hypothesis Space</h3>\n",
    "\n",
    "Each observation in $\\mathcal{D}$ acts as a constraint on what $f^*$ might be. The dataset, function, and loss function defines a surface over parameter space, and training means searching this surface for a good minimum.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{L}(\\theta) = \\frac{1}{n} \\sum \\mathcal{L}(f_\\theta(x_i), y_i)\n",
    "\\end{align*}\n",
    "\n",
    "<h3>üîΩ 4. We Minimize Loss via Optimization</h3>\n",
    "\n",
    "We explored gradient descent as a method to minimize the loss. We visualized how the landscape behaves, how gradients flow, and how descent leads to improvement ‚Äî but not always perfection.\n",
    "\n",
    "<h3>‚ùó 5. We Encounter Fundamental Errors</h3>\n",
    "\n",
    "We introduced three core sources of error in machine learning:\n",
    "- Approximation error: when our model can‚Äôt express the true function.\n",
    "- Generalization error: we dont have enough data to make a reliable estimate.\n",
    "- Optimization error: our optimizer didn‚Äôt find the best possible model.\n",
    "\n",
    "<h3>üß≠ Final Takeaway</h3>\n",
    "\n",
    "> **Machine learning is about hypothesis, assumptions, constraints - and how we use this to learn a function from data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5613ffbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ebdd8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
